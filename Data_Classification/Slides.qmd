---
format:
  revealjs:
    theme: serif
    code-fold: true
    controls: true
    navigation-mode: linear
    controls-layout: bottom-right
    controls-tutorial: true
    slide-number: true
    show-slide-number: all
    pdfMaxPagesPerSlide: 1
fig-dpi: 300

---


Classifying Data
================

::::{.columns}
:::{.column width="100%"}

Finding patterns in complex datasets, emphasizing aspects we think are important.
:::
::::


Descriptive Statistics
----------------------


::::{.columns}
:::{.column width="100%"}

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
| **Operation** | **Nominal** | **Ordinal** | **Interval** | **Ratio** |
| Equality | x | x | x | x |
| Counts/Mode | x | x | x | x |
| Rank/Order |  | x | x | x |
| Median |  | ~ | x | x |
| Add/Subtract |  |  | x | x |
| Mean |  |  | x | x |
| Multiply/Divide |  |  |  | x |


:::
::::


Measures of Central Tendency
----------------------------


::::{.columns}
:::{.column width="100%"}


Highlight the "central" feature in a dataset.


* **Mode**: The most frequent value in a set
* **Median**: The middle value in a set
	+ Data is ranked to find the center point
	
		- 50% above, 50% below+ Not impacted by outliers
* **Mean**: The sum of all values divided by the number of values
	+ Impacted by outliers


:::
::::


Measures of Dispersion
----------------------

::::{.columns}
:::{.column width="100%"}

These statistics give context a measure of central tendency.


* **Range**: Difference between the maximum and minimum
* **Inter-quartile Range**: 75th to 25th percentile
  + Spread around the median, not influenced by outliers

* **Standard Deviation**: $\sigma = \sqrt{\frac{1}{N}\sum\_{i=1}^n (x\_i - U)^2}$
  + Spread around the mean(U), influenced by outliers


:::
::::


Frequency Distribution
----------------------

Frequency of occurrence, typically in a **qualitative** dataset.

* **Bar charts** help visualize frequency distributions
  * Counts per category

![](images/Frequency_Dist.svg)


Probability Distribution
------------------------


::::{.columns}
:::{.column width="50%"}


Probability of occurrence in a **quantitative** dataset.

* **Normal Distribution**: 
  + Idealized, based on distance from the mean in **standard deviations**.
  + Assumed in many statistical tests.

:::
:::{.column width="50%"}


![](images/normal_dist.svg)

|  |  |
| --- | --- |
| ±1 $\sigma$ | 68% obs. |
| ±2 $\sigma$ | 95% obs. |
| ±3 $\sigma$ | 99.7% obs. |

:::
::::


Histograms
----------

Sorts and groups data into **bins** of consistent width.

::::{.columns}
:::{.column width="50%"}

* Approximate a probability distribution
  + Grouping data into classes
  + Outlier detection

* Not the same as bar charts

:::
:::{.column width="50%"}

![](images/histogram.png)


:::
::::


Deviating from the Norm
-----------------------

Data rarely fits a normal distribution perfectly:

::::{.columns}
:::{.column width="50%"}

* **Skew**: deviates from a normal distribution
+ Tails with outliers

* **Kurtosis**: deviates from a normal distribution
+ Dispersed or clustered

:::
:::{.column width="50%"}

**Near Normal**


![](images/normal_dist.png)

:::
::::


Deviating from the Norm
-----------------------

Data rarely fits a normal distribution perfectly:

::::{.columns}
:::{.column width="50%"}

* **Skew**: deviates from a normal distribution
+ Tails with outliers

* **Kurtosis**: deviates from a normal distribution
+ Dispersed or clustered

:::
:::{.column width="50%"}

**Skewed Normal**

![](images/normal_dist2.png)

:::
::::


Deviating from the Norm
-----------------------

Data rarely fits a normal distribution perfectly:

::::{.columns}
:::{.column width="50%"}

* **Skew**: deviates from a normal distribution
+ Tails with outliers

* **Kurtosis**: deviates from a normal distribution
+ Dispersed or clustered

:::
:::{.column width="50%"}

**Highly Skewed**

![](images/normal_dist3.png)

:::
::::

TopHat Question 1
=================


::::{.columns}
:::{.column width="100%"}


If you are working with nominal or ordinal data, and you want see how many observations you have for each category, you would use:


* A histogram to plot a probability distribution
* A histogram to plot a frequency distribution
* A bar chart to plot a probability distribution
* A bar chart to plot a frequency distribution


:::
::::


Normalizing Data
----------------

Scaling a variable by another can reveal hidden patterns in our data.

::::{.columns}
:::{.column width="50%"}

+ Income vs. money spent on food

:::
:::{.column width="50%"}


![](images/confounder_1.png)

**Highly Correlated**


:::
::::


Normalizing Data
----------------

Scaling a variable by another can reveal hidden patterns in our data.

::::{.columns}
:::{.column width="50%"}

+ Income vs. money spent on food
+ Population vs. shape area

:::
:::{.column width="50%"}

![](images/confounder_2.png)

**No Correlation**

:::
::::

Multiple Confounders
--------------------

Not always straightforward to account for multiple variables.

::::{.columns}
:::{.column width="60%"}




* e.g., COVID by age groups

![](images/horgan.jpg)


:::
:::{.column width="40%"}


![](images/multiple_confounders.png)

:::
::::


Standardizing
-------------

Allow us to compare between **two or more** variables in different units / scales.

::::{.columns}
:::{.column width="50%"}

* $z = \frac{x-\overline{U}}{\sigma}$
* Similar to normalizing:
  + Remove the mean and standard deviation from multiple variables

:::
:::{.column width="50%"}

![](images/Standardizing.png)



:::
::::


TopHat Question 2
=================


::::{.columns}
:::{.column width="100%"}


Which of these countries has the highest population density? *Populations and Areas are approximate.*


* **Monaco**: Pop (37,000), Area (2 km2)
* **Singapore**: Pop (5,500,000), Area (720 km2)
* **China**: Pop (1,400,000,000), Area (9,600,000 km2)


:::
::::


Classification Methods
----------------------


::::{.columns}
:::{.column width="50%"}


**Unsupervised:**


* Data defined classes - the user decides on the number of classes
* The rest is left of up to an algorithm

:::
:::{.column width="50%"}


**Supervised:**


* User defined - the user explicitly defines classes
* Or provides set of classes as training data
* Degree of user input is variable, more than unsupervised


:::
::::


Common Examples in Arc Pro
--------------------------

Vancouver dissemination areas by population total: 

::::{.columns}
:::{.column width="50%"}

**Not classified**

* Color scheme is stretched between min/max
* Difficult to see patterns

:::
:::{.column width="50%"}

![](images/Unclassified.png)


:::
::::


Equal Interval
--------------

One of the simplest classification schemes.

::::{.columns}
:::{.column width="50%"}

* Data is split to classes of equal width based on the range.
* **Unsupervised**: user defines number of bins.

:::
:::{.column width="50%"}

![](images/Equal_Int.png)


:::
::::


Defined Interval
----------------

Another of the simplest classification schemes.

::::{.columns}
:::{.column width="50%"}

* Data is split to classes of equal width based on the range.
* **Unsupervised**: user defines bin width.

:::
:::{.column width="50%"}

![](images/Defined.png)


:::
::::


Quantiles
---------

Slightly more complex classification scheme.

::::{.columns}
:::{.column width="50%"}

* Data is split into classes by percentiles.
  + e.g. 0-20%, 20-40%, ... 80-100%.

* **Unsupervised**: user defines number of bins.

:::
:::{.column width="50%"}

![](images/Quantile.png)


:::
::::


Natural Breaks
--------------

More complex, data is split using the [Jenks algorithm](http://wiki.gis.com/wiki/index.php/Jenks_Natural_Breaks_Classification).

::::{.columns}
:::{.column width="50%"}


* Optimizes splits, by maximizing within group similarity and between group dissimilarity.
  + "Natural" classes.

* **Unsupervised**: user defines number of bins.

:::
:::{.column width="50%"}

![](images/Natural_break.png)


:::
::::


Standard Deviation
------------------

Informative to "experts", but not accessible for all audiences.


::::{.columns}
:::{.column width="50%"}

* "Distance" from mean in standard deviations.
  + Interval data: diverging color maps.

* **Unsupervised**: user defines number of bins.

:::
:::{.column width="50%"}

![](images/Standard_dev.png)


:::
::::


Manual Breaks
-------------

**Supervised**: User defines break values.


::::{.columns}
:::{.column width="50%"}

* Allows us to choose more meaningful break values if necessary.
* Incorporate multiple factors
* Influence the way the data is perceived.

:::
:::{.column width="50%"}

![](images/Natural_break.png)


:::
::::


TopHat Question 3
=================

This classification method seeks to maximize the similarity between data values within groups and maximize the dissimilarity in data values between groups. It tries to find the "optimal" splits within a dataset.


::::{.columns}
:::{.column width="50%"}

* Manual Breaks
* Quantiles
* Natural Breaks
:::
:::{.column width="50%"}

* Equal Interval
* Standard Deviation

:::
::::


More Complex Methods
--------------------


::::{.columns}
:::{.column width="100%"}


There are many classification methods that are a bit too complex to actually perform in this course.


* I'm introducing some because they are important to be aware of them.
  + You'll encounter them if you continue with GIS.


:::
::::


K-means
-------


::::{.columns}
:::{.column width="100%"}


Algorithm uses random steps to group data into clusters.


* **Unsupervised**: user defines number of bins & iterations.


![](images/kmeans.gif){}


:::
::::


Median Absolute Deviation
-------------------------

Frequently used for  automated outlier detection.

::::{.columns}
:::{.column width="50%"}




* **Unsupervised**: user defines error threshold.

:::
:::{.column width="50%"}

![](images/MAD.jpg)


:::
::::


Decision Trees
--------------

Fit training data to user defined categories.


::::{.columns}
:::{.column width="50%"}

* **Supervised**: user provides training classes.
* *Automated*: algorithm determines break values.
* Risk of over-fitting

:::
:::{.column width="50%"}

![](images/tree.png)


:::
::::


Random Forests
--------------

Multiple trees (>100) can be averaged to increase performance and generalization.


::::{.columns}
:::{.column width="50%"}

* **Supervised**: user provides training classes and "hyperparameters".
* *Automated*: algorithm determines break values.
* Low risk of over-fitting

:::
:::{.column width="50%"}

![](images/forest.gif)


:::
::::


Landscape Classification
------------------------

Multiple trees (>100) can be averaged to increase performance and generalization.

::::{.columns}
:::{.column width="50%"}


* **Supervised**: user provides training classes and "hyperparameters".
* *Automated*: algorithm determines break values.
* Low risk of over-fitting

:::
:::{.column width="20%"}

:::
:::{.column width="30%"}

![](images/FishIsland_NDVI2.gif)


:::
::::


Neural Networks
---------------

One of the most complex methods, an algorithm learns complex relationships in dataset.


::::{.columns}
:::{.column width="50%"}


* **Supervised**: user provides training classes and "hyperparameters".
* Risk of over-fitting
  + Requires careful inspection

:::
:::{.column width="50%"}

![](images/NN.gif)


:::
::::


TopHat Question 4
=================


::::{.columns}
:::{.column width="100%"}


Unsupervised classification methods typically require more user input than supervised classification methods.


* True
* False


:::
::::


